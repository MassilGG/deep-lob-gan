{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8Z8JVrn52+k2AMMt+xxcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MassilGG/deep-lob-gan/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3HwxAgsa-Cp",
        "outputId": "8d1fa1ae-d840-4c1c-8f85-246aa4525ca7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MassilGG/deep-lob-gan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9_0bW3W9ScO",
        "outputId": "084eb23c-ecb6-49b5-a105-5a74bd13d69e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-lob-gan'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 8 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (8/8), 2.41 MiB | 4.94 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Load LOBSTER files"
      ],
      "metadata": {
        "id": "_hSWhhgIdjcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"AMZN_2012-06-21_34200000_57600000\"\n",
        "book_path = f\"/content/{name}_orderbook_5.csv\"   # <-- change\n",
        "msg_path  = f\"/content/{name}_message_5.csv\"     # <-- change (recommended). If missing, set msg_path=None\n",
        "\n",
        "LEVELS = 5  # you said 5 levels\n",
        "DT_SEC = 10 # paper uses 10s; with 1 day only, consider 1-5s if too few samples\n",
        "DROP_OPEN_MIN = 30\n",
        "DROP_CLOSE_MIN = 30\n",
        "\n",
        "\n",
        "def read_lobster_book(path, levels=5, sep=\",\"):\n",
        "    \"\"\"\n",
        "    Reads LOBSTER orderbook file without header.\n",
        "    Common format (per level): ask_price_i, ask_size_i, bid_price_i, bid_size_i, repeated for i=1..levels\n",
        "    => total columns = 4*levels\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, header=None, sep=sep)\n",
        "    expected = 4 * levels\n",
        "    if df.shape[1] != expected:\n",
        "        raise ValueError(f\"Expected {expected} columns for {levels} levels, got {df.shape[1]}. \"\n",
        "                         \"Check sep delimiter or file format.\")\n",
        "    return df\n",
        "\n",
        "def read_lobster_message(path, sep=\",\"):\n",
        "    \"\"\"\n",
        "    Typical LOBSTER message columns:\n",
        "    0: time (seconds after midnight, float)\n",
        "    1: event type\n",
        "    2: order id\n",
        "    3: size\n",
        "    4: price\n",
        "    5: direction\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, header=None, sep=sep)\n",
        "    if df.shape[1] < 1:\n",
        "        raise ValueError(\"Message file seems empty or badly parsed.\")\n",
        "    return df\n",
        "\n",
        "# Try comma first, fallback to space\n",
        "def smart_read_book(path, levels=5):\n",
        "    for sep in [\",\", r\"\\s+\"]:\n",
        "        try:\n",
        "            return read_lobster_book(path, levels=levels, sep=sep)\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    raise last\n",
        "\n",
        "def smart_read_msg(path):\n",
        "    for sep in [\",\", r\"\\s+\"]:\n",
        "        try:\n",
        "            return read_lobster_message(path, sep=sep)\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    raise last\n",
        "\n",
        "msg_df = smart_read_msg(msg_path)\n",
        "time_sec = msg_df.iloc[:, 0].astype(float).values\n",
        "book_df = smart_read_book(book_path, levels=LEVELS)\n",
        "print(\"book_df shape:\", book_df.shape)\n",
        "print(\"time range (sec):\", float(time_sec[0]), \"->\", float(time_sec[-1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "w-xLF6Q5bjlA",
        "outputId": "37073192-bbbe-4d8e-e3a2-028010e60a7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/AMZN_2012-06-21_34200000_57600000_message_5.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3641230159.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mmsg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_read_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mtime_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mbook_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_read_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEVELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3641230159.py\u001b[0m in \u001b[0;36msmart_read_msg\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mmsg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_read_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3641230159.py\u001b[0m in \u001b[0;36msmart_read_msg\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\"\\s+\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mread_lobster_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3641230159.py\u001b[0m in \u001b[0;36mread_lobster_message\u001b[0;34m(path, sep)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Message file seems empty or badly parsed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AMZN_2012-06-21_34200000_57600000_message_5.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Resample to regular Δt grid"
      ],
      "metadata": {
        "id": "Vd6o6Nqide8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_book_last_in_bin(book_df, time_sec, dt_sec=10):\n",
        "    \"\"\"\n",
        "    Creates a regular time grid and keeps the last snapshot observed in each bin.\n",
        "    \"\"\"\n",
        "    t0, t1 = float(time_sec[0]), float(time_sec[-1])\n",
        "    grid = np.arange(t0, t1 + 1e-9, dt_sec)\n",
        "    idx = np.searchsorted(time_sec, grid, side=\"right\") - 1\n",
        "    idx[idx < 0] = 0\n",
        "    idx[idx >= len(book_df)] = len(book_df) - 1\n",
        "    resampled = book_df.iloc[idx].reset_index(drop=True)\n",
        "    return resampled, grid\n",
        "\n",
        "\n",
        "book_res, grid_sec = resample_book_last_in_bin(book_df, time_sec, dt_sec=DT_SEC)\n",
        "\n",
        "# Drop first/last 30 minutes of continuous trading session (paper-style)\n",
        "# Here we do it purely in clock time:\n",
        "open_cut = DROP_OPEN_MIN * 60\n",
        "close_cut = DROP_CLOSE_MIN * 60\n",
        "mask = (grid_sec >= grid_sec[0] + open_cut) & (grid_sec <= grid_sec[-1] - close_cut)\n",
        "book_res = book_res.loc[mask].reset_index(drop=True)\n",
        "grid_sec = grid_sec[mask]\n",
        "\n",
        "print(\"Resampled shape:\", book_res.shape)"
      ],
      "metadata": {
        "id": "_Lp6pgNJcNhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Build \"centered snapshot\" vector X_t of length 2k (k=LEVELS) using a price grid fixed at time t:\n",
        "- grid_prices_t = [bidP_k..bidP1, askP1..askP_k]\n",
        "- X_t = [ -bidS_k..-bidS1, +askS1..+askS_k ]\n",
        "- X_{t+dt} is computed on the SAME grid_prices_t by looking up sizes at t+dt (missing => 0).\n"
      ],
      "metadata": {
        "id": "xLLn4e84dvPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_level_columns(row, levels=5):\n",
        "    \"\"\"\n",
        "    Returns arrays (askP, askS, bidP, bidS) each length=levels.\n",
        "    Handles the common interleaved format:\n",
        "      [askP1, askS1, bidP1, bidS1, askP2, askS2, bidP2, bidS2, ...]\n",
        "    If your file is different, adapt here.\n",
        "    \"\"\"\n",
        "    arr = row.values.astype(float)\n",
        "    askP, askS, bidP, bidS = [], [], [], []\n",
        "    for i in range(levels):\n",
        "        base = 4*i\n",
        "        askP.append(arr[base + 0])\n",
        "        askS.append(arr[base + 1])\n",
        "        bidP.append(arr[base + 2])\n",
        "        bidS.append(arr[base + 3])\n",
        "    return np.array(askP), np.array(askS), np.array(bidP), np.array(bidS)\n",
        "\n",
        "def snapshot_on_own_grid(row, levels=5):\n",
        "    askP, askS, bidP, bidS = parse_level_columns(row, levels=levels)\n",
        "    # grid prices: bids from deep->best, then asks best->deep\n",
        "    grid_prices = np.concatenate([bidP[::-1], askP])\n",
        "    # signed sizes aligned with that grid\n",
        "    x = np.concatenate([-bidS[::-1], +askS])\n",
        "    return grid_prices, x\n",
        "\n",
        "def snapshot_on_given_grid(row, grid_prices, levels=5):\n",
        "    askP, askS, bidP, bidS = parse_level_columns(row, levels=levels)\n",
        "    # map price -> signed size (only top levels available)\n",
        "    mp = {}\n",
        "    for i in range(levels):\n",
        "        mp[float(bidP[i])] = -float(bidS[i])\n",
        "        mp[float(askP[i])] = +float(askS[i])\n",
        "    x = np.array([mp.get(float(p), 0.0) for p in grid_prices], dtype=float)\n",
        "    return x\n",
        "\n",
        "# Build pairs (S_t, X_{t+1}) where S_t = X_t (Markov)\n",
        "X_list, Y_list = [], []\n",
        "for t in range(len(book_res) - 1):\n",
        "    grid_prices_t, x_t = snapshot_on_own_grid(book_res.iloc[t], levels=LEVELS)\n",
        "    x_next_on_grid_t = snapshot_on_given_grid(book_res.iloc[t+1], grid_prices_t, levels=LEVELS)\n",
        "    X_list.append(x_t)\n",
        "    Y_list.append(x_next_on_grid_t)\n",
        "\n",
        "X = np.stack(X_list)  # (N-1, 2k)\n",
        "Y = np.stack(Y_list)  # (N-1, 2k)\n",
        "print(\"X,Y shapes:\", X.shape, Y.shape)"
      ],
      "metadata": {
        "id": "Zp8d06q4dv5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3bis) Visualisation of the X,y Data"
      ],
      "metadata": {
        "id": "U5aCn7JQhbrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = 100\n",
        "\n",
        "grid_prices, x = snapshot_on_own_grid(book_res.iloc[t], levels=LEVELS)\n",
        "k = len(grid_prices) // 2\n",
        "\n",
        "lob = pd.DataFrame({\n",
        "    \"price\": grid_prices,\n",
        "    \"bid_size\": np.r_[ -x[:k], np.zeros(k) ],\n",
        "    \"ask_size\": np.r_[ np.zeros(k), x[k:] ]\n",
        "})\n",
        "\n",
        "tick = np.min(np.diff(np.unique(lob[\"price\"])))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "ax.barh(lob[\"price\"], -lob[\"bid_size\"], height=0.8 * tick, label=\"Bids\")\n",
        "ax.barh(lob[\"price\"],  lob[\"ask_size\"], height=0.8 * tick, label=\"Asks\")\n",
        "\n",
        "ax.axvline(0, color=\"black\", linewidth=1)\n",
        "ax.set_xlabel(\"Size (bids left, asks right)\")\n",
        "ax.set_ylabel(\"Price\")\n",
        "ax.set_title(f\"Limit Order Book — t={t}\")\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H7l0ici2fMMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Signed-sqrt normalization (paper Eq. (18))\n",
        "\n",
        "x_norm = sign(x)*sqrt(|x|)/c"
      ],
      "metadata": {
        "id": "pyMj-IQ8esw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def signed_sqrt_norm(x, c):\n",
        "    return np.sign(x) * np.sqrt(np.abs(x)) / c\n",
        "\n",
        "def signed_sqrt_inv(xn, c):\n",
        "    return np.sign(xn) * (np.abs(xn) * c)**2\n",
        "\n",
        "# choose c from training data scale (robust)\n",
        "abs_sqrt = np.sqrt(np.abs(np.concatenate([X.flatten(), Y.flatten()])))\n",
        "c = np.percentile(abs_sqrt, 99.5) + 1e-8\n",
        "print(\"Normalization constant c =\", c)\n",
        "\n",
        "Xn = signed_sqrt_norm(X, c).astype(np.float32)\n",
        "Yn = signed_sqrt_norm(Y, c).astype(np.float32)"
      ],
      "metadata": {
        "id": "m5KWWIkhetBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = np.concatenate([X.flatten(), Y.flatten()])\n",
        "normed = signed_sqrt_norm(raw, c)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "axs[0].hist(raw, bins=200)\n",
        "axs[0].set_title(\"Raw signed volumes\")\n",
        "axs[0].set_yscale(\"log\")\n",
        "axs[0].grid(alpha=0.3)\n",
        "\n",
        "axs[1].hist(normed, bins=200)\n",
        "axs[1].set_title(\"After signed sqrt normalization\")\n",
        "axs[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BPazAZOghwiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Train/val split"
      ],
      "metadata": {
        "id": "lzyLNT85iL-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(Xn)\n",
        "perm = np.random.permutation(N)\n",
        "split = int(0.9 * N)\n",
        "tr_idx, va_idx = perm[:split], perm[split:]\n",
        "\n",
        "Xtr, Ytr = Xn[tr_idx], Yn[tr_idx]\n",
        "Xva, Yva = Xn[va_idx], Yn[va_idx]\n",
        "print(\"Train:\", Xtr.shape, \"Val:\", Xva.shape)"
      ],
      "metadata": {
        "id": "ZCfIzB95iLpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Torch Dataset"
      ],
      "metadata": {
        "id": "7N_K2yYPiRYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LobTransitionDataset(Dataset):\n",
        "    def __init__(self, Xcond, Ytarget):\n",
        "        self.X = torch.from_numpy(Xcond)\n",
        "        self.Y = torch.from_numpy(Ytarget)\n",
        "    def __len__(self): return self.X.shape[0]\n",
        "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
        "\n",
        "BATCH_SIZE = 512 if len(Xtr) >= 2048 else 128\n",
        "train_loader = DataLoader(LobTransitionDataset(Xtr, Ytr), batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(LobTransitionDataset(Xva, Yva), batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n"
      ],
      "metadata": {
        "id": "K2FdkpfsiRAe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}